# -*- coding: utf-8 -*-
"""Copy of dida 325 final project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFipFjh1CJCZN6nfcH4QjRtsTnI5BR9d

### **DIDA 325 Final Project: Gun-Related Mortality and Prevention**
Lillian Pulaski, Gabriella Coleman, Melanie Nguyen, Renzo Guevarra

**Introduction**

We are a team of analysts from a private firm who were contracted by the National Safety Council (NSC), an organization who is looking to expand their research and services towards gun-related issues, to analyze a comprehensive dataset from the CDC and other sources to uncover trends, identify at-risk populations, and recommend interventions. By combining our technical skills with a strong social justice lens, we aim to help NSC design strategies to reduce gun violence and save lives. Our diverse and intersectional identities within our team ensures that our analysis goes beyond the numbers, incorporating a deep understanding of the societal, cultural, and policy contexts behind the data.

This dataset includes data that FiveThirtyEight compiled from various sources; the CDC (Multiple Cause of Death Database), the FBI (police shootings), Mother Jones (mass shooting), and University of Maryland (Global Terrorism Database).

The columns in this dataset are all categoical by nature, with basic columns like year, month, sex, age, race, and education level. The columns intent and place provide information on the specific cause of death and where it occured. Police is a column with boolean variables (1 if shot by police, 0 if not shot by police). The hispanic column contains categorical codes which refer to the region the person is from based on the CDC's Hispanic Origin Code List (https://www.cdc.gov/nchs/data/dvs/Appendix_D_Accessible_Hispanic_Origin_Code_List_Update_2011.pdf).

### **Checkpoint 1**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

import statsmodels.api as sm

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor

from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error, r2_score

gun_deaths=pd.read_csv("https://raw.githubusercontent.com/fivethirtyeight/guns-data/refs/heads/master/full_data.csv")
gun_deaths=gun_deaths.drop(columns=['Unnamed: 0','place']) #dropping extra index and place columns since they aren't relevant to our research questions

gun_deaths.isna().sum()

"""The NAs in this data is concentrated in the 'education' column. There are 100798 total rows of data, and 1422 rows with NAs in education. Since this is a small fraction of the data, we are dropping the rows that don't have data for the education column."""

gun_deaths

"""### **Checkpoint 2**

Our four initial research questions we will be investigating will be comprehensive rather than specific so that by analyzing trends more generally, our team can deduce which certain demographics to investigate more in-depth (eg. certain demographics that show to be at more risk, most common intent across certain races, etc.). With our more specific questioning, we also strive to not exclude certain demographics that are known to be at higher risk and are typically ignored within data.

### 1. **What are the trends in gun-related deaths over time (2012â€“2014), and how do they vary by intent (homicide, suicide, legal intervention, accidental)?**

**Method:** Pandas to manipulate the data and group it by year and intent. Matplotlib/Seaborn to create line graphs, stacked bar charts, etc., to visualize trends in gun deaths by intent over the years.

**Why:** Understanding trends over time can provide insights into how gun violence is evolving and whether certain types of incidents are becoming more or less common.

### 2. **How do gun-related deaths differ across different demographic groups (age, sex, race, etc.)?**

**Method:** Pandas to group data by demographics to calculate and compare the number of deaths in each category. Seaborn to create bar plots and heatmaps to visualize the demographic breakdown of gun deaths.

**Why:** Understanding how gun deaths affect various demographic groups differently can highlight specific communities at higher risk and from there more in-depth analysis. Targeted interventions and policies from further analysis can then be subsequently implemented.

###**3. What is the relationship between education level and gun-related deaths?**

**Method:** Pandas to group data by education level and count the number of deaths in each group. Seaborn to explore how the distribution of gun-related deaths varies across different education levels.

**Why:** Research often shows that education level can correlate with various social outcomes, including gun-violence, criminal activity, and increased mental health issues. By analyzing this relationship, we can explore whether lower education levels are associated with higher rates of gun-related deaths.

### **4. Can we predict the likelihood of a gun-related death being classified as suicide based on demographic and characteristics (e.g., sex, police involvement, race, education)?**

**Method:** Logistic Regression to predict whether an incident is more likely to be a suicide based on features like sex, age, race, education level, etc.  Pandas (data manipulation), Seaborn (data visualization).

**Why:** Predicting what factors tend to be associated with a gun death being classified as a suicide based on available data can help in designing early intervention strategies. The results of the model can show what demographics and groups policy makers should be targeting to prevent suicides by firearms.
While we don't have any regional data so far, merging geographical locations of gun-related deaths can be of immense help in implementing strategies in particular areas throughout the United States.
"""

#creating modified dataset for research question 4 (dropping na rows for education)

gun_deaths4=gun_deaths.copy()
gun_deaths4=gun_deaths4.dropna(subset=['education','intent'])


gun_deaths4.isna().sum()

X=gun_deaths4[['police', 'sex', 'race', 'education']]
X=pd.get_dummies(X).astype("float32")

X.head()

y=(gun_deaths4['intent'] == 'Suicide').astype(int) #outcome is either intent was suicide (1) or not a suicide (0)

y.value_counts()

#making copy of original ds that drops the NAs in the relevant columns (education column has little over 1000 NAs which mess up the logistical regression results)
gun_deaths4 = gun_deaths.copy()
gun_deaths4 = gun_deaths4.dropna(subset=['education', 'intent', 'police', 'sex', 'race'])

X = gun_deaths4[['police', 'sex', 'race', 'education']]
X = pd.get_dummies(X, drop_first=True).astype("float32") #drops 1 dummy per category FIX (if dont drop, p values are 1 and results are all weird)

y = (gun_deaths4['intent'] == 'Suicide').astype(int)

X = sm.tools.tools.add_constant(X)

model = sm.Logit(y, X).fit(maxiter=100) #more iterations

print(model.summary())

phat=model.predict()
phat[0:10]

#predictions range from 0.53-0.93 -> model is predicting a fairly high probability of the outcome for observations

confusion=model.pred_table(threshold=0.5) #errors at 95% confidence
confusion

confusion.trace()/confusion.sum()*100

#83.07 model accuracy

#bar graph??  --> separate and make multiple graphs each for education, race..
#rename features to be more clear?


features = ['race_White', 'race_Black', 'education_Less than HS', 'education_HS/GED',
            'sex_M', 'race_Hispanic', 'education_Some college', 'race_Native American/Native Alaskan']

abs_coefficients = [1.5751, 1.8508, 1.4282, 0.9249, 0.7688, 0.5361, 0.4919, 0.4850]

importance_df = pd.DataFrame({
    'Feature': features,
    'Absolute Importance': abs_coefficients})

importance_df = importance_df.sort_values('Absolute Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.set_style("darkgrid")
ax = sns.barplot(x='Absolute Importance', y='Feature', data=importance_df, color='#98AFC7')

plt.title('Feature Importance for Predicting Likelihood of Gun Death Being A Suicide', fontsize=14)
plt.xlabel('Absolute Coefficient Value', fontsize=12)
plt.ylabel('Feature', fontsize=12)

plt.show()

"""EXPLAINATION FOR QUESTION 4


pseudo r-squared is 0.3503 pretty -> okay predictive power

strong negative coef for police -> rare occurrences of suicide by police (isnt even significant p 0.996 and has insane standard error)
drop the police all together??

SEX AND RACE
black and hispanic people significant neg coef -> less at risk

looking at significant positive coef -> male, native american, white (white is strongest)

important to consider data only includes gun suicides (excludes all other methods)
to prevent/lower gun suicides -> mainly focus on white males??



EDUCATION
higgher edu lvels more likely to die by suicide -> maybe means to focus on people wokring higher level jobs (stress??)


"""

